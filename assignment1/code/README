

6d)
for lr in 0.01 0.1 0.2 0.5; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr $lr " & done done

6d.2)
for momentum in 0.0 0.5 0.9; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -momentum $momentum " & done done

6e)
for unit in 20 100 200 500; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr 0.01 -momentum 0.5 -hidden_layer_1_dimension $unit " & done done
6f)

stringg=" "

for lr in 0.01 0.02 0.03 0.04 0.05 0.07 0.09 0.1 0.2 0.3 0.4 0.5 0.7; do nohup condor_run "python train.py -lr $lr $stringg"  & done 

for momentum in 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9; do nohup condor_run "python train.py -momentum $momentum $stringg"  & done

for unit in 20 50 100 200 300 400 500; do nohup condor_run "python train.py -hidden_layer_1_dimension $unit $stringg"  & done

for epoch in 20 30 50 70 100 125 150 200 300; do nohup condor_run "python train.py -max_epoch $epoch $stringg" & done

for lbd in 0.001 0.002 0.003 0.004 0.005 0.007 0.01; do nohup condor_run "python train.py -lbd $lbd $stringg" & done

6g) 


follows 6f) except we are having two layers now 
EXCEPT THE VARIABLE 
	stringg=" -hidden_layer_2_dimension 100 "



6h)

for iter in 1 2 3 4 5; do nohup condor_run "python train.py -activation tanh -momentum 0.5 " & done

for iter in 1 2 3 4 5; do nohup condor_run "python train.py -activation ReLU -momentum 0.5 " & done

for iter in 1 2 3 4 5; do nohup condor_run "python train.py -activation tanh -momentum 0.5 -hidden_layer_2_dimension 100" & done

for iter in 1 2 3 4 5; do nohup condor_run "python train.py -activation ReLU -momentum 0.5 -hidden_layer_2_dimension 100" & done

 
