5a) For the default configuration, lr=0.01, hidden_unit=100, k=1, simply run,  
	python train.py

For a parameter sweep over different stopping criteria (epoch numbers),
for lr in 0.1 0.01; do for epoch in 250 300 350 400 500 600 750 1000; do nohup condor_run "python train.py -k 1 -lr $lr -max_epoch $epoch " & done done

for k in 5 10 20; do nohup condor_run "python train.py -k $k -max_epoch 1000 " & done

5c) python 5c.py ../dump/ [learned model name] 


5d)

5e) python train_autoencoder2.py -max_epoch 30 


5f)


5g) for hidden in 50 100 200 500; do nohup condor_run "python train.py -n_hidden $hidden -max_epoch 500" & done







6d)
for lr in 0.01 0.1 0.2 0.5; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr $lr " & done done

6d.2)
for momentum in 0.0 0.5 0.9; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -momentum $momentum " & done done

6e)
for unit in 20 100 200 500; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr 0.01 -momentum 0.5 -hidden_layer_1_dimension $unit " & done done
6f)

stringg=" "

for lr in 0.01 0.02 0.03 0.04 0.05 0.07 0.09 0.1 0.2 0.3 0.4 0.5 0.7; do nohup condor_run "python train.py -lr $lr $stringg"  & done 

for momentum in 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9; do nohup condor_run "python train.py -momentum $momentum $stringg"  & done

for unit in 20 50 100 200 300 400 500; do nohup condor_run "python train.py -hidden_layer_1_dimension $unit $stringg"  & done

for epoch in 20 30 50 70 100 125 150 200 300; do nohup condor_run "python train.py -max_epoch $epoch $stringg" & done

for lbd in 0.001 0.002 0.003 0.004 0.005 0.007 0.01; do nohup condor_run "python train.py -lbd $lbd $stringg" & done

6g) 


follows 6f) except we are having two layers now 
EXCEPT THE VARIABLE 
	stringg=" -hidden_layer_2_dimension 100 "
EXCEPT

for unit in 20 50 100 200 300 400 500; do nohup condor_run "python train.py -lr 0.01 -momentum 0.2 -max_epoch 125 -hidden_layer_1_dimension $unit -hidden_layer_2_dimension $unit"  & done

6h)

The simplest invocation is python train.py -minibatch_size 32

for activation in "sigmoid" "tanh" "ReLU"; do for iter in 1 2 3; do for size in 1 32 64 128; do nohup condor_run "python train.py -lr 0.01 -activation $activation -minibatch_size $size" & done done done

for lr in 0.01 0.1 0.2 0.5; do for iter in 1 2 3; do nohup condor_run "python train.py -lr $lr -minibatch_size 32 " & done done 

for batch_normalization in "True" "False"; do for iter in 1 2 3; do nohup condor_run "python train.py -lr 0.01 -minibatch_size 32 -batch_normalization $batch_normalization " & done done 
6i)

for activation in "sigmoid" "tanh" "ReLU"; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr 0.01 -momentum 0.5 -activation $activation" & done done

for activation in "sigmoid" "tanh" "ReLU"; do for iter in 1 2 3 4 5; do nohup condor_run "python train.py -lr 0.01 -momentum 0.5 -hidden_layer_2_dimension 100 -activation $activation " & done done

